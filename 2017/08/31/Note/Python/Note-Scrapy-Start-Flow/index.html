<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    

    

    
<!-- Baidu Tongji -->
<script>var _hmt = _hmt || []</script>
<script async src="//hm.baidu.com/hm.js?cb4be66237379541488b8502a6eca006"></script>
<!-- End Baidu Tongji -->




    <meta charset="utf-8">
    
    
    
    
    <title>(原创)Scrapy之命令行启动流程 | 大地小神 | 你们都是大傻瓜, 我是天下大赢家</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Python">
    <meta name="description" content="dummy          code{white-space: pre-wrap;}       span.smallcaps{font-variant: small-caps;}       span.underline{text-decoration: underline;}       div.column{display: inline-block; vert">
<meta name="keywords" content="Python">
<meta property="og:type" content="article">
<meta property="og:title" content="(原创)Scrapy之命令行启动流程">
<meta property="og:url" content="https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/index.html">
<meta property="og:site_name" content="大地小神">
<meta property="og:description" content="dummy          code{white-space: pre-wrap;}       span.smallcaps{font-variant: small-caps;}       span.underline{text-decoration: underline;}       div.column{display: inline-block; vert">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-06-04T13:49:29.597Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="(原创)Scrapy之命令行启动流程">
<meta name="twitter:description" content="dummy          code{white-space: pre-wrap;}       span.smallcaps{font-variant: small-caps;}       span.underline{text-decoration: underline;}       div.column{display: inline-block; vert">
    
        <link rel="alternate" type="application/atom+xml" title="大地小神" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">qrsforever</h5>
          <a href="mailto:985612771@qq.com" title="985612771@qq.com" class="mail">985612771@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/qrsforever" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://gitee.com/lidongai" target="_blank" >
                <i class="icon icon-lg icon-code-fork"></i>
                Gitee
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="http://weibo.com/705723886/" target="_blank" >
                <i class="icon icon-lg icon-weibo"></i>
                Weibo
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://twitter.com/qrsforever" target="_blank" >
                <i class="icon icon-lg icon-twitter"></i>
                Twitter
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/2017/08/30/CV"  >
                <i class="icon icon-lg icon-user-circle"></i>
                Author
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">(原创)Scrapy之命令行启动流程</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">(原创)Scrapy之命令行启动流程</h1>
        <h5 class="subtitle">
            
                <time datetime="2017-08-31T08:01:00.000Z" itemprop="datePublished" class="page-time">
  2017-08-31
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Note/">Note</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#scrapy-命令启动"><span class="post-toc-text">0.1 Scrapy 命令启动</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#scrapy-crawl-执行流程"><span class="post-toc-text">0.1.1 scrapy crawl 执行流程</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#crawler-spider和engine"><span class="post-toc-text">0.1.2 Crawler, Spider和Engine</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-Note/Python/Note-Scrapy-Start-Flow"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">(原创)Scrapy之命令行启动流程</h1>
        <div class="post-meta">
            <time class="post-time" title="2017-08-31 16:01:00" datetime="2017-08-31T08:01:00.000Z"  itemprop="datePublished">2017-08-31</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Note/">Note</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang xml:lang>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>dummy</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; } /* Alert */
code span.an { color: #008000; } /* Annotation */
code span.at { } /* Attribute */
code span.bu { } /* BuiltIn */
code span.cf { color: #0000ff; } /* ControlFlow */
code span.ch { color: #008080; } /* Char */
code span.cn { } /* Constant */
code span.co { color: #008000; } /* Comment */
code span.cv { color: #008000; } /* CommentVar */
code span.do { color: #008000; } /* Documentation */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.im { } /* Import */
code span.in { color: #008000; } /* Information */
code span.kw { color: #0000ff; } /* Keyword */
code span.op { } /* Operator */
code span.ot { color: #ff4000; } /* Other */
code span.pp { color: #ff4000; } /* Preprocessor */
code span.sc { color: #008080; } /* SpecialChar */
code span.ss { color: #008080; } /* SpecialString */
code span.st { color: #008080; } /* String */
code span.va { } /* Variable */
code span.vs { color: #008080; } /* VerbatimString */
code span.wa { color: #008000; font-weight: bold; } /* Warning */
  </style>
  <link rel="stylesheet" href="/css/pandoc.css">
</head>
<body>
<!-- vim-markdown-toc GFM -->
<ul>
<li><a href="#scrapy-命令启动">Scrapy 命令启动</a>
<ul>
<li><a href="#scrapy-crawl-执行流程">scrapy crawl 执行流程</a></li>
<li><a href="#crawler-spider和engine">Crawler, Spider和Engine</a></li>
</ul></li>
</ul>
<!-- vim-markdown-toc -->
<a id="more"></a>
<pre><code>

                     +------------------------------&gt;  Settings  &lt;-------------------------------------------------+
                     |                                    |                       settings.py                      |
                     ◆                                    | extend           +-------------------+                 |
               ScrapyCommand                              ▽                  | SPIDER_MIDDLEWARES|                 |
                △      |                              BaseSettings           | ITEM_PIPELINES    |                 |
                |      |                                  |                  | SPIDER_MODULES    |                 |
                |      o---&gt; add_options()                |                  +-------------------+                 |
                |      |                                  o---&gt; setmodule()         |                              |
                |      |                                  |            |            |                              |
             Command   o---&gt; process_options()            |            |------------+                              |
                |      |                                  o---&gt; set &lt;--|                                           |
                |      |                                  |            =                                           |
                |      o---&gt; virtual run()                |                                                        |
                |                                                                                                  |
         crawl  o---&gt; run()                                                                                        |
           |    |      |                                     command:                                              |
           |    |      |  ★                     1           +-------------------------------------------------+    |
           |    =      +---&gt; crawler_process.crawl()        |                                                 |    |
           |           |                                    | scrapy crawl --nolog s51job -o /tmp/result.csv  |    |
           |           |                        5           |                                                 |    |
           |           +---&gt; crawler_process.start()        +-------------------------------------------------+    |
           |           |                                                                                           |
           |                                                                                                       |
           |                            extend                               crawlers 1:n                          |
           o----&gt; CrawlerProcess -----------------------▷  CrawlerRunner  ◆-----------------------&gt;  Crawler ◇-----+
           |            |                                        |                  s51job         /   |
           |            |                                        |           2                    /    | ★
                        o---&gt; start()                            o---&gt; create_crawler()          /     o---&gt; crawl() &lt;--------+
                        |        |                               |           |                  /      |                      |
                        |        |                               |           |                 /       |                      |
                        |        +---&gt; reactor.getThreadPool()   |           +----------------/        o---&gt; _create_spider   |
                        |        |                               |                     |               |                      |
                        |        |                               |                     |               |                      |
                        |        +---&gt; reactor.run()             |                     +------+        o---&gt; _create_engine() |
                        |        |                               o---&gt; stop()                 |        |                      |
                        |        =                               |                            |        =                      |
                        |                                        |                            |                               |
                        o---&gt; _stop_reactor                      o---&gt; join()                SpiderLoader                     |
                        |                                        |                                |                           |
                        =                                        |       4                        |                           |
                                                                 o---&gt; crawl()                    o---&gt; _load_all_spiders()   |
                                                                 |       |                        |                           |
               Spider ◁----- CrawlSpider ◁----- S51jobSpider     |       |                        |         3                 |
                   |          |                          \       =       +---&gt; crawler.crawl()    o---&gt; load(name)            |
                   |          |                           \              |                |       |                           |
    start_urls &lt;---o          o---&gt; rules                  \                              |       =                           |
                   |          |                             \  is                         |                                   |
                   |          |                              ------- _create_spider() &lt;---+ spider                            |
       parse() &lt;---o          o---&gt; parse_start_url()                                     |                              &lt;----+
                   |          |                                    6                      |
                   |          =                                      _create_engine() &lt;---+ engine
                   |                                              /                       |
                   o---&gt; start_requests()                     is /                        |
                   |       yield ☜                              /                         =
                   =                       ExecutionEngine -----
                                              ◆     |
                                              |     | ★           7
                                              |     o---&gt; open_spider()              +------------------+
                                              |     |                                |                  |
        Slot &lt;--------------------------------+     |                                |                  |
         |                                          o---&gt; start()                    |  Twisted Deffer  |
         |                                          |                                |                  |
         o---&gt; nextcall()                           |                                |                  |
         |                                          o---&gt; stop/pause/close()         +------------------+
         |                                          |
         o---&gt; scheduler()                          |
         |                                          o---&gt; download/schedule/crawl()
         |        8                                 |
         o---&gt; heartbeat()-----------+              |
         |      |                    |              o---&gt; _next_request()
         =      | task.LoopingCall() |              |
                +--------------------+              =
</code></pre>
<h2 id="scrapy-命令启动"><span class="header-section-number">0.1</span> Scrapy 命令启动</h2>
<h3 id="scrapy-crawl-执行流程"><span class="header-section-number">0.1.1</span> scrapy crawl 执行流程</h3>
<p><strong>bin/scrapy</strong>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1"> <span class="dv">7</span> <span class="im">from</span> scrapy.cmdline <span class="im">import</span> execute</a>
<a class="sourceLine" id="cb2-2" title="2"> <span class="dv">8</span></a>
<a class="sourceLine" id="cb2-3" title="3"> <span class="dv">9</span> <span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:</a>
<a class="sourceLine" id="cb2-4" title="4"><span class="dv">10</span>     sys.argv[<span class="dv">0</span>] <span class="op">=</span> re.sub(<span class="vs">r&#39;(-script\.pyw|\.exe)?$&#39;</span>, <span class="st">&#39;&#39;</span>, sys.argv[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb2-5" title="5"><span class="dv">11</span>     sys.exit(execute())</a></code></pre></div>
<p><strong>scrapy/cmdline.py</strong>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1"> <span class="dv">97</span> <span class="kw">def</span> execute(argv<span class="op">=</span><span class="va">None</span>, settings<span class="op">=</span><span class="va">None</span>):</a>
<a class="sourceLine" id="cb3-2" title="2"> <span class="dv">98</span>     <span class="cf">if</span> argv <span class="kw">is</span> <span class="va">None</span>:</a>
<a class="sourceLine" id="cb3-3" title="3"> <span class="dv">99</span>         argv <span class="op">=</span> sys.argv</a>
<a class="sourceLine" id="cb3-4" title="4"><span class="dv">100</span></a>
<a class="sourceLine" id="cb3-5" title="5"><span class="dv">101</span>     <span class="co"># --- backwards compatibility for scrapy.conf.settings singleton ---</span></a>
<a class="sourceLine" id="cb3-6" title="6"><span class="dv">102</span>     <span class="cf">if</span> settings <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> <span class="st">&#39;scrapy.conf&#39;</span> <span class="kw">in</span> sys.modules:</a>
<a class="sourceLine" id="cb3-7" title="7"><span class="dv">103</span>         <span class="im">from</span> scrapy <span class="im">import</span> conf</a>
<a class="sourceLine" id="cb3-8" title="8"><span class="dv">104</span>         <span class="cf">if</span> <span class="bu">hasattr</span>(conf, <span class="st">&#39;settings&#39;</span>):</a>
<a class="sourceLine" id="cb3-9" title="9"><span class="dv">105</span>             settings <span class="op">=</span> conf.settings</a>
<a class="sourceLine" id="cb3-10" title="10"><span class="dv">106</span>     <span class="co"># ------------------------------------------------------------------</span></a>
<a class="sourceLine" id="cb3-11" title="11"><span class="dv">107</span></a>
<a class="sourceLine" id="cb3-12" title="12"><span class="dv">108</span>     <span class="cf">if</span> settings <span class="kw">is</span> <span class="va">None</span>:</a>
<a class="sourceLine" id="cb3-13" title="13"><span class="dv">109</span>         settings <span class="op">=</span> get_project_settings()</a>
<a class="sourceLine" id="cb3-14" title="14"><span class="dv">110</span>         <span class="co"># set EDITOR from environment if available</span></a>
<a class="sourceLine" id="cb3-15" title="15"><span class="dv">111</span>         <span class="cf">try</span>:</a>
<a class="sourceLine" id="cb3-16" title="16"><span class="dv">112</span>             editor <span class="op">=</span> os.environ[<span class="st">&#39;EDITOR&#39;</span>]</a>
<a class="sourceLine" id="cb3-17" title="17"><span class="dv">113</span>         <span class="cf">except</span> <span class="pp">KeyError</span>: <span class="cf">pass</span></a>
<a class="sourceLine" id="cb3-18" title="18"><span class="dv">114</span>         <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb3-19" title="19"><span class="dv">115</span>             settings[<span class="st">&#39;EDITOR&#39;</span>] <span class="op">=</span> editor</a>
<a class="sourceLine" id="cb3-20" title="20"><span class="dv">116</span>     check_deprecated_settings(settings)</a>
<a class="sourceLine" id="cb3-21" title="21"><span class="dv">117</span></a>
<a class="sourceLine" id="cb3-22" title="22"><span class="dv">118</span>     <span class="co"># --- backwards compatibility for scrapy.conf.settings singleton ---</span></a>
<a class="sourceLine" id="cb3-23" title="23"><span class="dv">119</span>     <span class="im">import</span> warnings</a>
<a class="sourceLine" id="cb3-24" title="24"><span class="dv">120</span>     <span class="im">from</span> scrapy.exceptions <span class="im">import</span> ScrapyDeprecationWarning</a>
<a class="sourceLine" id="cb3-25" title="25"><span class="dv">121</span>     <span class="cf">with</span> warnings.catch_warnings():</a>
<a class="sourceLine" id="cb3-26" title="26"><span class="dv">122</span>         warnings.simplefilter(<span class="st">&quot;ignore&quot;</span>, ScrapyDeprecationWarning)</a>
<a class="sourceLine" id="cb3-27" title="27"><span class="dv">123</span>         <span class="im">from</span> scrapy <span class="im">import</span> conf</a>
<a class="sourceLine" id="cb3-28" title="28"><span class="dv">124</span>         conf.settings <span class="op">=</span> settings</a>
<a class="sourceLine" id="cb3-29" title="29"><span class="dv">125</span>     <span class="co"># ------------------------------------------------------------------</span></a>
<a class="sourceLine" id="cb3-30" title="30"><span class="dv">126</span></a>
<a class="sourceLine" id="cb3-31" title="31"><span class="dv">127</span>     inproject <span class="op">=</span> inside_project()</a>
<a class="sourceLine" id="cb3-32" title="32"><span class="dv">128</span>     cmds <span class="op">=</span> _get_commands_dict(settings, inproject)</a>
<a class="sourceLine" id="cb3-33" title="33"><span class="dv">129</span>     cmdname <span class="op">=</span> _pop_command_name(argv)</a>
<a class="sourceLine" id="cb3-34" title="34"><span class="dv">130</span>     parser <span class="op">=</span> optparse.OptionParser(formatter<span class="op">=</span>optparse.TitledHelpFormatter(), <span class="op">\</span></a>
<a class="sourceLine" id="cb3-35" title="35"><span class="dv">131</span>         conflict_handler<span class="op">=</span><span class="st">&#39;resolve&#39;</span>)</a>
<a class="sourceLine" id="cb3-36" title="36"><span class="dv">132</span>     <span class="cf">if</span> <span class="kw">not</span> cmdname:</a>
<a class="sourceLine" id="cb3-37" title="37"><span class="dv">133</span>         _print_commands(settings, inproject)</a>
<a class="sourceLine" id="cb3-38" title="38"><span class="dv">134</span>         sys.exit(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb3-39" title="39"><span class="dv">135</span>     <span class="cf">elif</span> cmdname <span class="kw">not</span> <span class="kw">in</span> cmds:</a>
<a class="sourceLine" id="cb3-40" title="40"><span class="dv">136</span>         _print_unknown_command(settings, cmdname, inproject)</a>
<a class="sourceLine" id="cb3-41" title="41"><span class="dv">137</span>         sys.exit(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb3-42" title="42"><span class="dv">138</span></a>
<a class="sourceLine" id="cb3-43" title="43"><span class="dv">139</span>     cmd <span class="op">=</span> cmds[cmdname]</a>
<a class="sourceLine" id="cb3-44" title="44"><span class="dv">140</span>     parser.usage <span class="op">=</span> <span class="st">&quot;scrapy </span><span class="sc">%s</span><span class="st"> </span><span class="sc">%s</span><span class="st">&quot;</span> <span class="op">%</span> (cmdname, cmd.syntax())</a>
<a class="sourceLine" id="cb3-45" title="45"><span class="dv">141</span>     parser.description <span class="op">=</span> cmd.long_desc()</a>
<a class="sourceLine" id="cb3-46" title="46"><span class="dv">142</span>     settings.setdict(cmd.default_settings, priority<span class="op">=</span><span class="st">&#39;command&#39;</span>)</a>
<a class="sourceLine" id="cb3-47" title="47"><span class="dv">143</span>     cmd.settings <span class="op">=</span> settings</a>
<a class="sourceLine" id="cb3-48" title="48"><span class="dv">144</span>     cmd.add_options(parser)</a>
<a class="sourceLine" id="cb3-49" title="49"><span class="dv">145</span>     opts, args <span class="op">=</span> parser.parse_args(args<span class="op">=</span>argv[<span class="dv">1</span>:])</a>
<a class="sourceLine" id="cb3-50" title="50"><span class="dv">146</span>     _run_print_help(parser, cmd.process_options, args, opts)</a>
<a class="sourceLine" id="cb3-51" title="51"><span class="dv">147</span></a>
<a class="sourceLine" id="cb3-52" title="52"><span class="dv">148</span>     cmd.crawler_process <span class="op">=</span> CrawlerProcess(settings)</a>
<a class="sourceLine" id="cb3-53" title="53"><span class="dv">149</span>     _run_print_help(parser, _run_command, cmd, args, opts)</a>
<a class="sourceLine" id="cb3-54" title="54"><span class="dv">150</span>     sys.exit(cmd.exitcode)</a>
<a class="sourceLine" id="cb3-55" title="55"><span class="dv">151</span></a>
<a class="sourceLine" id="cb3-56" title="56"><span class="dv">152</span> <span class="kw">def</span> _run_command(cmd, args, opts):</a>
<a class="sourceLine" id="cb3-57" title="57"><span class="dv">153</span>     <span class="cf">if</span> opts.profile:</a>
<a class="sourceLine" id="cb3-58" title="58"><span class="dv">154</span>         _run_command_profiled(cmd, args, opts)</a>
<a class="sourceLine" id="cb3-59" title="59"><span class="dv">155</span>     <span class="cf">else</span>:</a>
<a class="sourceLine" id="cb3-60" title="60"><span class="dv">156</span>         cmd.run(args, opts)</a></code></pre></div>
<p>前大部分对参数和工程Setting解析处理, 最后_run_print_help --&gt;_run_command --&gt; cmd.run, 这里的cmd实际上就是crawl</p>
<p><strong>commands/crawl.py</strong>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1"><span class="dv">50</span>     <span class="kw">def</span> run(<span class="va">self</span>, args, opts):</a>
<a class="sourceLine" id="cb4-2" title="2"><span class="dv">51</span>         <span class="cf">if</span> <span class="bu">len</span>(args) <span class="op">&lt;</span> <span class="dv">1</span>:</a>
<a class="sourceLine" id="cb4-3" title="3"><span class="dv">52</span>             <span class="cf">raise</span> UsageError()</a>
<a class="sourceLine" id="cb4-4" title="4"><span class="dv">53</span>         <span class="cf">elif</span> <span class="bu">len</span>(args) <span class="op">&gt;</span> <span class="dv">1</span>:</a>
<a class="sourceLine" id="cb4-5" title="5"><span class="dv">54</span>             <span class="cf">raise</span> UsageError(<span class="st">&quot;running &#39;scrapy crawl&#39; with more than one spider is no longer supported&quot;</span>)</a>
<a class="sourceLine" id="cb4-6" title="6"><span class="dv">55</span>         spname <span class="op">=</span> args[<span class="dv">0</span>]</a>
<a class="sourceLine" id="cb4-7" title="7"><span class="dv">56</span></a>
<a class="sourceLine" id="cb4-8" title="8"><span class="dv">57</span>         <span class="va">self</span>.crawler_process.crawl(spname, <span class="op">**</span>opts.spargs)</a>
<a class="sourceLine" id="cb4-9" title="9"><span class="dv">58</span>         <span class="va">self</span>.crawler_process.start()</a></code></pre></div>
<p>继续调用crawler_process对象中crawl,start方法, 即CrawlerProcess, 其父类CrawlerRunner实现crawl方法</p>
<p><strong>crawler.py</strong>:</p>
<pre><code>110 class CrawlerRunner(object):
144     def crawl(self, crawler_or_spidercls, *args, **kwargs):
166         crawler = self.create_crawler(crawler_or_spidercls)
167         return self._crawl(crawler, *args, **kwargs)
181     def create_crawler(self, crawler_or_spidercls):
192         if isinstance(crawler_or_spidercls, Crawler):
193             return crawler_or_spidercls
194         return self._create_crawler(crawler_or_spidercls)
195
196     def _create_crawler(self, spidercls):
197         if isinstance(spidercls, six.string_types):
198             spidercls = self.spider_loader.load(spidercls)
199         return Crawler(spidercls, self.settings)</code></pre>
<p>crawler_or_spidercls spider名字, 经过spider_loader.load()转换为对应的spider对象(父类CrawlSpider), 这一步很关键, 自己实现的spider 继承CrawlSpider. self.spider_loader: scrapy.spiderloader.SpiderLoader</p>
<p><strong>spiderloader.py</strong>:</p>
<pre><code>15 class SpiderLoader(object):
16     &quot;&quot;&quot;
17     SpiderLoader is a class which locates and loads spiders
18     in a Scrapy project.
19     &quot;&quot;&quot;
20     def __init__(self, settings):
21         self.spider_modules = settings.getlist(&#39;SPIDER_MODULES&#39;)
22         self.warn_only = settings.getbool(&#39;SPIDER_LOADER_WARN_ONLY&#39;)
23         self._spiders = {}
24         self._found = defaultdict(list)
25         self._load_all_spiders()
    ...
44     def _load_all_spiders(self):
45         for name in self.spider_modules:
47                 for module in walk_modules(name):
48                     self._load_spiders(module)</code></pre>
<p>SPIDER_MODULES: 当前工程settings.py变量 _load_all_spiders: 加载所有自定义的spider</p>
<p><strong>crawler.py</strong>:</p>
<pre><code>27 class Crawler(object):
28
70     def crawl(self, *args, **kwargs):
71         assert not self.crawling, &quot;Crawling already taking place&quot;
72         self.crawling = True
73
74         try:
75             self.spider = self._create_spider(*args, **kwargs)
76             self.engine = self._create_engine()
77             start_requests = iter(self.spider.start_requests())
78             yield self.engine.open_spider(self.spider, start_requests)
79             yield defer.maybeDeferred(self.engine.start)
80         except Exception:
89             self.crawling = False
90             if self.engine is not None:
91                 yield self.engine.close()
92
93             if six.PY2:
94                 six.reraise(*exc_info)
95             raise

97     def _create_spider(self, *args, **kwargs):
98         return self.spidercls.from_crawler(self, *args, **kwargs)</code></pre>
<p>self.spidercls.from_crawler调入到CrawlSpider</p>
<p><strong>spiders/crawl.py</strong>:</p>
<pre><code> 34 class CrawlSpider(Spider):
 35
 98     @classmethod
 99     def from_crawler(cls, crawler, *args, **kwargs):
100         spider = super(CrawlSpider, cls).from_crawler(crawler, *args, **kwargs)
101         spider._follow_links = crawler.settings.getbool(
102             &#39;CRAWLSPIDER_FOLLOW_LINKS&#39;, True)
103         return spider</code></pre>
<p><strong>spiders/<strong>init</strong>.py</strong>:</p>
<pre><code>18 class Spider(object_ref):
49     @classmethod
50     def from_crawler(cls, crawler, *args, **kwargs):
51         spider = cls(*args, **kwargs)
52         spider._set_crawler(crawler)
53         return spider
</code></pre>
<p>到此应该知道自己的spider 如何创建的了</p>
<h3 id="crawler-spider和engine"><span class="header-section-number">0.1.2</span> Crawler, Spider和Engine</h3>
<p><strong>scrapy/crawler.py</strong>:</p>
<pre><code> 27 class Crawler(object):
     ...
 70     def crawl(self, *args, **kwargs):
 71         assert not self.crawling, &quot;Crawling already taking place&quot;
 72         self.crawling = True
 73
 74         try:
 75             self.spider = self._create_spider(*args, **kwargs)
 76             self.engine = self._create_engine()
    ...
 97     def _create_spider(self, *args, **kwargs):
 98         return self.spidercls.from_crawler(self, *args, **kwargs)
 99
100     def _create_engine(self):
101         return ExecutionEngine(self, lambda _: self.stop())
</code></pre>
<p>ExecutionEngine 结构:</p>
<pre><code>▼ ExecutionEngine : class
   +__init__ : function
   +start : function
   +stop : function
   +close : function
   +pause : function
   +unpause : function
   +_next_request : function
   +_needs_backout : function
   +_next_request_from_scheduler : function
   +_handle_downloader_output : function
   +spider_is_idle : function
   +open_spiders : function
   +has_capacity : function
   +crawl : function
   +schedule : function
   +download : function
   +_downloaded : function
  ▼+_download : function
     +_on_success : function
     +_on_complete : function
   +open_spider : function
   +_spider_idle : function
  ▼+close_spider : function
    ▼+log_failure : function
       +errback : function
   +_close_all_spiders : function
   +_finish_stopping_engine : function</code></pre>
<p><strong>core/engine.py</strong>:</p>
<pre><code> 56 class ExecutionEngine(object):
 57
 58     def __init__(self, crawler, spider_closed_callback):
 59         self.crawler = crawler
 60         self.settings = crawler.settings
 61         self.signals = crawler.signals
 62         self.logformatter = crawler.logformatter
 63         self.slot = None
 64         self.spider = None
 65         self.running = False
 66         self.paused = False
 67         self.scheduler_cls = load_object(self.settings[&#39;SCHEDULER&#39;])
 68         downloader_cls = load_object(self.settings[&#39;DOWNLOADER&#39;])
 69         self.downloader = downloader_cls(crawler)
 70         self.scraper = Scraper(crawler)
 71         self._spider_closed_callback = spider_closed_callback
    ...
253     def open_spider(self, spider, start_requests=(), close_if_idle=True):
254         assert self.has_capacity(), &quot;No free spider slot when opening %r&quot; % \
255             spider.name
256         logger.info(&quot;Spider opened&quot;, extra={&#39;spider&#39;: spider})
257         nextcall = CallLaterOnce(self._next_request, spider)
258         scheduler = self.scheduler_cls.from_crawler(self.crawler)
259         start_requests = yield self.scraper.spidermw.process_start_requests(start_requests, spider)
260         slot = Slot(start_requests, close_if_idle, nextcall, scheduler)
261         self.slot = slot
262         self.spider = spider
263         yield scheduler.open(spider)
264         yield self.scraper.open_spider(spider)
265         self.crawler.stats.open_spider(spider)
266         yield self.signals.send_catch_log_deferred(signals.spider_opened, spider=spider)
267         slot.nextcall.schedule()
268         slot.heartbeat.start(5)
</code></pre>
<p><strong>Setting</strong></p>
<table>
<thead>
<tr class="header">
<th>name</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SCHEDULER</td>
<td>scrapy.core.scheduler.Scheduler</td>
</tr>
<tr class="even">
<td>DOWNLOADER</td>
<td>scrapy.core.downloader.Downloader</td>
</tr>
<tr class="odd">
<td>DUPEFILTER_CLASS</td>
<td>scrapy.dupefilters.RFPDupeFilter</td>
</tr>
<tr class="even">
<td>SCHEDULER_PRIORITY_QUEUE</td>
<td>queuelib.PriorityQueue</td>
</tr>
<tr class="odd">
<td>SCHEDULER_DISK_QUEUE</td>
<td>scrapy.squeues.PickleLifoDiskQueue</td>
</tr>
<tr class="even">
<td>SCHEDULER_MEMORY_QUEUE</td>
<td>scrapy.squeues.LifoMemoryQueue</td>
</tr>
<tr class="odd">
<td>SPIDER_LOADER_CLASS</td>
<td>scrapy.spiderloader.SpiderLoader</td>
</tr>
</tbody>
</table>
</body>
</html>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2019-06-04T13:49:29.597Z" itemprop="dateUpdated">2019-06-04 21:49:29</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="https://qrsforever.github.io">
            <img src="/img/avatar.jpg" alt="qrsforever">
            qrsforever
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/&title=《(原创)Scrapy之命令行启动流程》 — 大地小神&pic=https://qrsforever.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/&title=《(原创)Scrapy之命令行启动流程》 — 大地小神&source=


  
  
  
  dummy
  
      code{white-space: pre-wrap;}
      span.smallcap..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《(原创)Scrapy之命令行启动流程》 — 大地小神&url=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/&via=https://qrsforever.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2017/09/01/Note/Python/Note-Twisted-Deffered-Machanism/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">(原创)笔记-Twisted的Deffered机制</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2017/08/30/Tutorial/Markdown/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">(原创)Tutorial for Markdown</h4>
      </a>
    </div>
  
</nav>



    











    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <!-- <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script> -->
    <script src="/js/av-min.js"></script>
    <script src="/js/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail,link'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'false' == 'true',
            verify: 'false' == 'true',
            appId: "bpShGWdW8DpODhnDko5O2IBB-gzGzoHsz",
            appKey: "rwmasTllBbHE69ADuLjFyFWf",
            avatar: "mm",
            placeholder: "Just go go",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->










</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢打赏!
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>qrsforever &copy; 2017 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/&title=《(原创)Scrapy之命令行启动流程》 — 大地小神&pic=https://qrsforever.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/&title=《(原创)Scrapy之命令行启动流程》 — 大地小神&source=


  
  
  
  dummy
  
      code{white-space: pre-wrap;}
      span.smallcap..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《(原创)Scrapy之命令行启动流程》 — 大地小神&url=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/&via=https://qrsforever.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=https://qrsforever.github.io/2017/08/31/Note/Python/Note-Scrapy-Start-Flow/" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>










<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- lidong cha. -->
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- lidong end. -->

</body>
</html>
